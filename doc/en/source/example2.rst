*****************************************
Define and test a service topology
*****************************************

In FogFlow a service topology is defined as a graph of several tasks. 
Each task in the service topology is annotated with its inputs and outputs, 
which indicate their dependency to the other tasks in the same topology. 
Different from fog functions, a service topology is triggerred on demand by a customized "requirement" object. 


With a simple example we explain how developers can define and test a service topology in the following section. 


Use case on anomaly detection
---------------------------------------


This use case study is for retail stores to detect abnormal energy consumption in real-time.
As illustrated in the following picture, a retail company has a large number of shops distributed in different locations. 
For each shop, a Raspberry Pi device (edge node) is deployed to monitor the power consumption from all PowerPanels 
in the shop. Once an abnormal power usage is detected on the edge, 
the alarm mechanism in the shop is triggered to inform the shop owner. 
Moreover, the detected event is reported to the cloud for information aggregation. 
The aggregated information is then presented to the system operator via a dashboard service. 
In addition, the system operator can dynamically update the rule for anomaly detection.


.. figure:: figures/retails.png
   :width: 100 %


* Anomaly Detector: This operator is to detect anomaly events based on the collected data from power panels in a retail store. It has two types of inputs: 

	* detection rules, which are provided and updated by the operator; The detection rules input stream type is associated with ``broadcast``, meaning that the rules are needed by all task instances of this operator. The granularity of this operator is based on ``shopID``, meaning that a dedicated task instance will be created and configured for each shop. 	
	* sensor data from power panel

* Counter: This operator is to count the total number of anomaly events for all shops in each city. Therefore, its task granularity is by ``city``. Its input stream type is the output stream type of the previous operator (Anomaly Detector). 

There are two types of result consumers: (1) a dashboard service in the cloud, which subscribes to the final aggregation results generated by the counter operator for the global scope; (2) the alarm in each shop, which subscribes to the anomaly events generated by the Anomaly Detector task on the local edge node in the retail store. 

.. figure:: figures/retail-flow.png
   :width: 70 %

Specify a service topology
-----------------------------------

Using the graphical editor provided by FogFlow task designer, 
we define the following service topology for this use case. 

.. figure:: figures/retail-topology.png
   :width: 100 %

As seen in the picture, the following important information must be provided. 

#. define topology profile, including

	* topology name: the unique name of your topology
	* service description: some text to describe what this service is about
	* priority: define the priority level of all tasks in your topology, which will be utilized by edge nodes to decide how resource should be assigned to tasks 
	* resource usage: define if the tasks in this topology can use the resources on edge nodes in an exclusive way, meaning that not sharing resources with any task from the other topologies

#. draw the graph of data processing flows within the service topology

	With a right click at some place of the design board, you will see a memu pops up 
	and then you can start to choose either task or input streams 
	to define your data processing flows according to the design you had in mind. 

#. define Task Profile for each task in the data flow, including

	As shown in the following picture, you can start to specify the profile of each task in the data processing flow
	by clicking the configuration button. The following information is required to specify a task profile. 
	
	* name: the name of the task 
	* operator: the name of the operator that implements the data processing logic of this task; please register your operator beforehand so that it can be shown from the list. 
	* groupby: to determine how many instances of this task should be created on the fly; currently including the following cases: 
	
		- if ther is only one instance to be created for this task, please use "groupby" = "all"
		- if you need to create one instance for each entity ID of the input streams, please user "groupby" = "entityID"
		- if you need to create one instance for each unique value of some specific context metadata, please use the name of this registered context metadata
	
	* shuffling of input streams: to indicate how the input stream should be assigned to the instance(s) of this task during the runtime, including the following two cases: 
	
		- "shuffling" = "broadcast": the selected input streams should be repeatedly assigned to every task instance of this operator
		- "shuffling" = "unicast": each of the selected input streams should be assigned to a specific task instance only once	
	
	* entity type of output streams: to specify the entity type of the produced output stream


Trigger the service topology by sending a customized requirement
------------------------------------------------------------------------------

Once developers submit a specified service topology and the implemented operators, 
the service data processing logic can be triggered on demand by a high level processing requirement. 
The processing requirement is sent as NGSI10 update, with the following properties: 

* topology: which topology to trigger
* expected output: the output stream type expected by external subscribers
* scope: a defined geoscope for the area where input streams should be selected
* scheduler: which type of scheduling method should be chosen by Topology Master for task assignment

Here is the Javascript-based code example to register a service topology object. 

.. code-block:: javascript

    var topologyCtxObj = {};
    
    topologyCtxObj.entityId = {
        id : 'Topology.' + topology.name, 
        type: topology.name,
        isPattern: false
    };
    
    topologyCtxObj.attributes = {};   
    topologyCtxObj.attributes.status = {type: 'string', value: 'enabled'};
    topologyCtxObj.attributes.template = {type: 'object', value: topology};    
    
	// assume the config.brokerURL is the IP of cloud IoT Broker
    var client = new NGSI10Client(config.brokerURL);	

	// send NGSI10 update	
    client.updateContext(topologyCtxObj).then( function(data) {
        console.log(data);                
    }).catch( function(error) {
        console.log('failed to submit the topology');
    });


